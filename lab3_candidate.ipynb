{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOOGgU23CkO-"
      },
      "outputs": [],
      "source": [
        "#LAB3 CANDIDATE ELIMINATION\n",
        "\n",
        "import csv\n",
        "\n",
        "with open(\"trainingexamples.csv\") as f:\n",
        "    csv_file = csv.reader(f)\n",
        "    data = list(csv_file)\n",
        "\n",
        "    specific = data[0][:-1]\n",
        "    general = [['?' for i in range(len(specific))] for j in range(len(specific))]\n",
        "\n",
        "    step=1 #for printing purpose\n",
        "    for i in data:\n",
        "        if i[-1] == \"Y\":\n",
        "            for j in range(len(specific)):\n",
        "                if i[j] != specific[j]:\n",
        "                    specific[j] = \"?\"\n",
        "                    general[j][j] = \"?\"\n",
        "\n",
        "        elif i[-1] == \"N\":\n",
        "            for j in range(len(specific)):\n",
        "                if i[j] != specific[j]:\n",
        "                    general[j][j] = specific[j]\n",
        "                else:\n",
        "                    general[j][j] = \"?\"\n",
        "\n",
        "        print(\"\\nStep {} of candidate elimination algo\".format(step))\n",
        "        step+=1\n",
        "        print(specific)\n",
        "        print(general)\n",
        "\n",
        "    gh = [] # gh = general Hypothesis\n",
        "    for i in general:\n",
        "        for j in i:\n",
        "            if j != '?':\n",
        "                gh.append(i)\n",
        "                break\n",
        "    print(\"\\nFinal Specific hypothesis:\\n\", specific)\n",
        "    print(\"\\nFinal General hypothesis:\\n\", gh)"
      ]
    }
  ]
}