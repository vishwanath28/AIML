{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPT1csLHsJrEwoDa3rabdO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#LAB9 - LOCALLY WEIGHTED REGRESSION\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def local_regression(x0, X, Y, tau):\n","    x0 = [1, x0]   \n","    X = [[1, i] for i in X]\n","    X = np.asarray(X)\n","    xw = (X.T) * np.exp(np.sum((X - x0) ** 2, axis=1) / (-2 * (tau**2)))\n","    beta = (np.linalg.pinv(xw @ X)) @ (xw @ Y)   \n","    return (beta @ x0)   \n","\n","def draw(tau):\n","    prediction = [local_regression(x0, X, Y, tau) for x0 in domain]\n","    plt.plot(X, Y, 'o', color='black')\n","    plt.plot(domain, prediction, color='red')\n","    plt.show()\n","\n","X = np.linspace(-3, 3, num=1000)\n","domain = X\n","Y = np.log(np.abs((X ** 2) - 1) + .5)\n","draw(10)\n","draw(0.1)\n","draw(0.01)\n","draw(0.001)"],"metadata":{"id":"rer0Rlgaomp8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esWz2yc4eKHR"},"outputs":[],"source":["#LAB 8-KNN\n","#import the dataset and library files\n","from sklearn.datasets import load_iris\n","from sklearn.neighbors import KNeighborsClassifier\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","iris_dataset=load_iris()\n","\n","#display the iris dataset\n","print(\"\\n IRIS FEATURES \\ TARGET NAMES: \\n \", iris_dataset.target_names)\n","for i in range(len(iris_dataset.target_names)):\n","    print(\"\\n[{0}]:[{1}]\".format(i,iris_dataset.target_names[i]))\n","\n","print(\"\\n IRIS DATA :\\n\",iris_dataset[\"data\"])\n","print(\"\\n Target :\\n\",iris_dataset[\"target\"])\n","\n","\n","#split the data into training and testing data\n","X_train, X_test, y_train, y_test = train_test_split(iris_dataset[\"data\"], iris_dataset[\"target\"], random_state=0)\n","\n","print(\"\\n X TRAIN \\n\", X_train)\n","print(\"\\n X TEST \\n\", X_test)\n","print(\"\\n Y TRAIN \\n\", y_train)\n","print(\"\\n Y TEST \\n\", y_test)\n","\n","#train and fit the model\n","kn = KNeighborsClassifier(n_neighbors=5)\n","kn.fit(X_train, y_train)\n","\n","#predicting from model\n","x_new = np.array([[5, 2.9, 1, 0.2]])\n","print(\"\\n XNEW \\n\",x_new)\n","prediction = kn.predict(x_new)\n","print(\"\\n Predicted target value: {}\\n\".format(prediction))\n","print(\"\\n Predicted feature name: {}\\n\".format(iris_dataset[\"target_names\"][prediction]))\n","\n","#predict for entire test dataset\n","for i in range(len(X_test)):\n","  x = X_test[i]\n","  x_new = np.array([x])\n","  prediction = kn.predict(x_new)     #predict method returns label \n","  print(\"\\n Actual : {0} {1}, Predicted :{2}{3}\".format(y_test[i],iris_dataset[\"target_names\"][y_test[i]],prediction,iris_dataset[\"target_names\"][ prediction]))\n","\n","print(\"\\n TEST SCORE[ACCURACY]: {:.2f}\\n\".format(kn.score(X_test, y_test)))"]},{"cell_type":"code","source":["#LAB7 KMEANS VS EM\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","from sklearn.cluster import KMeans\n","from sklearn.mixture import GaussianMixture \n","import sklearn.metrics as sm\n","import pandas as pd\n","import numpy as np\n","\n","iris = datasets.load_iris()\n","\n","X = pd.DataFrame(iris.data)\n","X.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n","Y = pd.DataFrame(iris.target)\n","Y.columns = ['Targets']\n","\n","print(X)\n","print(Y)\n","colormap = np.array(['red', 'lime', 'black'])\n","\n","plt.subplot(1,2,1)\n","plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[Y.Targets], s=40)\n","plt.title('Real Clustering')\n","\n","model1 = KMeans(n_clusters=3)\n","model1.fit(X)\n","\n","plt.subplot(1,2,2)\n","plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model1.labels_], s=40)\n","plt.title('K Mean Clustering')\n","plt.show()\n","\n","model2 = GaussianMixture(n_components=3) \n","model2.fit(X)\n","\n","plt.subplot(1,2,1)\n","plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model2.predict(X)], s=40)\n","plt.title('EM Clustering')\n","plt.show()\n","\n","print(\"Actual Target is:\\n\", iris.target)\n","print(\"K Means:\\n\",model1.labels_)\n","print(\"EM:\\n\",model2.predict(X))\n","print(\"Accuracy of KMeans is \",sm.accuracy_score(Y,model1.labels_))\n","print(\"Accuracy of EM is \",sm.accuracy_score(Y, model2.predict(X)))\n"],"metadata":{"id":"TbcQHKbOpMLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB6 NAIVE BAYES\n","import csv\n","import random\n","import math\n","from statistics import mean,stdev\n","\n","def loadcsv(filename):\n","    dataset = list(csv.reader(open(filename,\"r\")))\n","    for i in range(len(dataset)):\n","        dataset[i] = [float(x) for x in dataset[i]]\n","    return dataset\n","\n","def summarizeByClass(dataset):\n","    separated = {}\n","    for i in range(len(dataset)):\n","        vector = dataset[i]\n","        if (vector[-1] not in separated):\n","            separated[vector[-1]] = []\n","        separated[vector[-1]].append(vector)\n","    summaries = {}\n","    for classValue, instances in separated.items():\n","        summaries[classValue] = [(mean(attribute), stdev(attribute)) for attribute in zip(*instances)][:-1]\n","    return summaries\n","\n","def calculateProbability(x, mean, stdev):\n","    exponent = math.exp(-1*((x-mean)**2)/(2*(stdev**2)))\n","    return (1 / math.sqrt(2*math.pi*(stdev**2))) * exponent\n","\n","def predict(summaries, inputVector):\n","    probabilities = {}\n","    for classValue, classSummaries in summaries.items():\n","        probabilities[classValue] = 1\n","        for i in range(len(classSummaries)):\n","            mean, stdev = classSummaries[i]\n","            x = inputVector[i]\n","            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n","    bestLabel, bestProb = None, -1\n","    for classValue, probability in probabilities.items():\n","        if bestLabel is None or probability > bestProb:\n","            bestProb = probability\n","            bestLabel = classValue\n","    return bestLabel\n","\n","def getPredictions(testSet, summaries ):\n","    predictions = []\n","    for i in range(len(testSet)):\n","        result = predict(summaries, testSet[i])\n","        predictions.append(result)\n","    return predictions\n","\n","def getAccuracy(testSet, predictions):\n","    correct = 0\n","    for i in range(len(testSet)):\n","        if testSet[i][-1] == predictions[i]:\n","            correct += 1\n","    return (correct/(len(testSet))) * 100.0\n","\n","filename = 'diabetes2.csv'\n","splitRatio = 0.9\n","dataset = loadcsv(filename)\n","actual = []\n","trainsize=int(splitRatio*len(dataset))\n","trainingSet=dataset[:trainsize]\n","testSet=dataset[trainsize:]\n","\n","for i in range(len(testSet)):\n","\tvector = testSet[i]\n","\tactual.append(vector[-1])\n"," \n","print('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), len(trainingSet), len(testSet)))\n","summaries = summarizeByClass(trainingSet) #will have (mean,sd) for all attributes.(for class 1 & 0 separately)\n","predictions = getPredictions(testSet,summaries)\n","print('\\nActual values:\\n',actual)\n","print(\"\\nPredictions:\\n\",predictions)\n","accuracy = getAccuracy(testSet, predictions)\n","print(\"Accuracy\",accuracy)\n"],"metadata":{"id":"m4Nd4-Sgo7T7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB5 ANN\n","import numpy as np\n","X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n","y = np.array(([92], [86], [89]), dtype=float)\n","X = X/np.amax(X,axis=0)\n","y = y/100\n","\n","#Sigmoid Function\n","def sigmoid (x):\n","    return 1/(1 + np.exp(-x))\n","\n","#Derivative of Sigmoid Function\n","def derivatives_sigmoid(x):\n","    return x * (1 - x)\n","\n","#Variable initialization\n","epoch=5000 \t\n","lr=0.1 \t\t\n","inputlayer_neurons = 2 \t\t\n","hiddenlayer_neurons = 3 \t\n","output_neurons = 1 \t\t\n","\n","#weight and bias initialization\n","wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))  #2,3\n","bh=np.random.uniform(size=(1,hiddenlayer_neurons))                   #1,3\n","wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))    #3,1\n","bout=np.random.uniform(size=(1,output_neurons))                      #1,1\n","\n","for i in range(epoch):\n","#Forward Propogation \n","    hinp=np.dot(X,wh)+ bh\n","    hlayer_act = sigmoid(hinp)      \n","    outinp=np.dot(hlayer_act,wout)+ bout\n","    output = sigmoid(outinp)\n","\n","    outgrad = derivatives_sigmoid(output) \n","    hiddengrad = derivatives_sigmoid(hlayer_act)\n","    \n","    EO = y-output                   \n","    d_output = EO* outgrad\n","\n","    EH = np.dot(d_output,wout.T)      \n","    d_hiddenlayer = EH * hiddengrad\n","\n","    wout += np.dot(hlayer_act.T, d_output) *lr      \n","    wh += np.dot(X.T,d_hiddenlayer) *lr\n","\n","print(\"Input: \\n\" + str(X)) \n","print(\"Actual Output: \\n\" + str(y))\n","print(\"Predicted Output: \\n\" ,output)"],"metadata":{"id":"pMpI3C4ipK3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB1 ASTAR\n","Graph_nodes = {\n","    'A': [('B', 6), ('F', 3)],\n","    'B': [('C', 3), ('D', 2)],\n","    'C': [('D', 1), ('E', 5)],\n","    'D': [('C', 1), ('E', 8)],\n","    'E': [('I', 5), ('J', 5)],\n","    'F': [('G', 1),('H', 7)] ,\n","    'G': [('I', 3)],\n","    'H': [('I', 2)],\n","    'I': [('E', 5), ('J', 3)],\n","     \n","}\n","\n","def get_neighbors(v):\n","    if v in Graph_nodes:\n","        return Graph_nodes[v]\n","    else:\n","        return None\n","        \n","def h(n):\n","        H_dist = {\n","            'A': 10,\n","            'B': 8,\n","            'C': 5,\n","            'D': 7,\n","            'E': 3,\n","            'F': 6,\n","            'G': 5,\n","            'H': 3,\n","            'I': 1,\n","            'J': 0             \n","        }\n","        return H_dist[n]\n","        \n","def aStarAlgo(start_node, stop_node):\n","         \n","        open_set = set(start_node) \n","        closed_set = set()\n","        g = {} \n","        parents = {}\n","        g[start_node] = 0\n","        parents[start_node] = start_node\n","        \n","        while len(open_set) > 0:\n","            n = None\n","\n","            for v in open_set:\n","                if n == None or g[v] + h(v) < g[n] + h(n):\n","                    n = v\n","     \n","            if n == stop_node or Graph_nodes[n] == None:\n","                pass\n","            else:\n","                for (m, weight) in get_neighbors(n):\n","                    if m not in open_set and m not in closed_set:\n","                        open_set.add(m)\n","                        parents[m] = n\n","                        g[m] = g[n] + weight\n","                         \n","                    else:\n","                        if g[m] > g[n] + weight:\n","                            g[m] = g[n] + weight\n","                            parents[m] = n\n","                            if m in closed_set:\n","                                closed_set.remove(m)\n","                                open_set.add(m)\n"," \n","            if n == None:\n","                print('Path does not exist!')\n","                return None\n","            if n == stop_node:\n","                path = []\n"," \n","                while parents[n] != n:\n","                    path.append(n)\n","                    n = parents[n]\n"," \n","                path.append(start_node)\n"," \n","                path.reverse()\n"," \n","                print('Path found: {}'.format(path))\n","                return path\n","            open_set.remove(n)\n","            closed_set.add(n)\n"," \n","        print('Path does not exist!')\n","        return None\n","\n","aStarAlgo('A', 'J')       \n","        \n","        \n","        \n","    "],"metadata":{"id":"rl8XvA2umC8_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB3 CANDIDATE ELIMINATION\n","\n","import csv\n","\n","with open(\"trainingexamples.csv\") as f:\n","    csv_file = csv.reader(f)\n","    data = list(csv_file)\n","\n","    specific = data[1][:-1]\n","    general = [['?' for i in range(len(specific))] for j in range(len(specific))]\n","\n","    for i in data:\n","        if i[-1] == \"Yes\":\n","            for j in range(len(specific)):\n","                if i[j] != specific[j]:\n","                    specific[j] = \"?\"\n","                    general[j][j] = \"?\"\n","\n","        elif i[-1] == \"No\":\n","            for j in range(len(specific)):\n","                if i[j] != specific[j]:\n","                    general[j][j] = specific[j]\n","                else:\n","                    general[j][j] = \"?\"\n","\n","        print(\"\\nStep \" + str(data.index(i)+1) + \" of Candidate Elimination Algorithm\")\n","        print(specific)\n","        print(general)\n","\n","    gh = [] # gh = general Hypothesis\n","    for i in general:\n","        for j in i:\n","            if j != '?':\n","                gh.append(i)\n","                break\n","    print(\"\\nFinal Specific hypothesis:\\n\", specific)\n","    print(\"\\nFinal General hypothesis:\\n\", gh)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1Rcx8u5xIYN","executionInfo":{"status":"ok","timestamp":1672259353696,"user_tz":-330,"elapsed":8,"user":{"displayName":"easy cse","userId":"02059060062089913408"}},"outputId":"f58bf50c-27b1-4e03-d90f-5380eea60837"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Step 1 of Candidate Elimination Algorithm\n","['sunny', 'warm', 'high', 'strong', 'warm', 'same']\n","[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n","\n","Step 2 of Candidate Elimination Algorithm\n","['sunny', 'warm', 'high', 'strong', 'warm', 'same']\n","[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n","\n","Step 3 of Candidate Elimination Algorithm\n","['sunny', 'warm', 'high', 'strong', 'warm', 'same']\n","[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n","\n","Step 4 of Candidate Elimination Algorithm\n","['sunny', 'warm', 'high', 'strong', 'warm', 'same']\n","[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n","\n","Final Specific hypothesis:\n"," ['sunny', 'warm', 'high', 'strong', 'warm', 'same']\n","\n","Final General hypothesis:\n"," []\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oCadCa6bzLjc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TDA4SKMXxIsz"},"execution_count":null,"outputs":[]}]}