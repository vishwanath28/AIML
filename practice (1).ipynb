{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiXRD5QPTUgFgg+pI/TRA1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#LAB1 ASTAR\n","Graph_nodes = {\n","    'A': [('B', 6), ('F', 3)],\n","    'B': [('C', 3), ('D', 2)],\n","    'C': [('D', 1), ('E', 5)],\n","    'D': [('C', 1), ('E', 8)],\n","    'E': [('I', 5), ('J', 5)],\n","    'F': [('G', 1),('H', 7)] ,\n","    'G': [('I', 3)],\n","    'H': [('I', 2)],\n","    'I': [('E', 5), ('J', 3)],\n","     \n","}\n","\n","def get_neighbors(v):\n","    if v in Graph_nodes:\n","        return Graph_nodes[v]\n","    else:\n","        return None\n","        \n","def h(n):\n","        H_dist = {\n","            'A': 10,\n","            'B': 8,\n","            'C': 5,\n","            'D': 7,\n","            'E': 3,\n","            'F': 6,\n","            'G': 5,\n","            'H': 3,\n","            'I': 1,\n","            'J': 0             \n","        }\n","        return H_dist[n]\n","        \n","def aStarAlgo(start_node, stop_node):\n","         \n","        open_set = set(start_node) \n","        closed_set = set()\n","        g = {} \n","        parents = {}\n","        g[start_node] = 0\n","        parents[start_node] = start_node\n","        \n","        while len(open_set) > 0:\n","            n = None\n","\n","            for v in open_set:\n","                if n == None or g[v] + h(v) < g[n] + h(n):\n","                    n = v\n","     \n","            if n == stop_node or Graph_nodes[n] == None:\n","                pass\n","            else:\n","                for (m, weight) in get_neighbors(n):\n","                    if m not in open_set and m not in closed_set:\n","                        open_set.add(m)\n","                        parents[m] = n\n","                        g[m] = g[n] + weight\n","                         \n","                    else:\n","                        if g[m] > g[n] + weight:\n","                            g[m] = g[n] + weight\n","                            parents[m] = n\n","                            if m in closed_set:\n","                                closed_set.remove(m)\n","                                open_set.add(m)\n"," \n","            if n == None:\n","                print('Path does not exist!')\n","                return None\n","            if n == stop_node:\n","                path = []\n"," \n","                while parents[n] != n:\n","                    path.append(n)\n","                    n = parents[n]\n"," \n","                path.append(start_node)\n"," \n","                path.reverse()\n"," \n","                print('Path found: {}'.format(path))\n","                return path\n","            open_set.remove(n)\n","            closed_set.add(n)\n"," \n","        print('Path does not exist!')\n","        return None\n","\n","aStarAlgo('A', 'J')       \n","        \n","        \n","        \n","    "],"metadata":{"id":"rl8XvA2umC8_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB2\n","class Graph:\n","    def __init__(self, graph, heuristicNodeList, startNode):  \n","        \n","        self.graph = graph\n","        self.H=heuristicNodeList\n","        self.start=startNode\n","        self.parent={}\n","        self.status={}\n","        self.solutionGraph={}\n","     \n","    def applyAOStar(self):         \n","        self.aoStar(self.start, False)\n","\n","    def getNeighbors(self, v):     \n","        return self.graph.get(v,'')\n","    \n","    def getStatus(self,v):         \n","        return self.status.get(v,0)  \n","    \n","    def setStatus(self,v, val):    \n","        self.status[v]=val\n","    \n","    def getHeuristicNodeValue(self, n):\n","        return self.H.get(n,0)     \n","\n","    def setHeuristicNodeValue(self, n, value):\n","        self.H[n]=value            \n","        \n","    \n","    def printSolution(self):\n","        print(\"FOR GRAPH SOLUTION, TRAVERSE THE GRAPH FROM THE START NODE:\",self.start)\n","        print(\"------------------------------------------------------------\")\n","        print(self.solutionGraph)\n","        print(\"------------------------------------------------------------\")\n","    \n","    def computeMinimumCostChildNodes(self, v):       \n","        minimumCost=0\n","        costToChildNodeListDict={}\n","        costToChildNodeListDict[minimumCost]=[]\n","        flag=True\n","        for nodeInfoTupleList in self.getNeighbors(v):  \n","            cost=0\n","            nodeList=[]\n","            for c, weight in nodeInfoTupleList:\n","                cost=cost+self.getHeuristicNodeValue(c)+weight\n","                nodeList.append(c)\n","            \n","            if flag==True:                       \n","                minimumCost=cost\n","                costToChildNodeListDict[minimumCost]=nodeList     \n","                flag=False\n","            else:                                  \n","                if minimumCost>cost:\n","                    minimumCost=cost\n","                    costToChildNodeListDict[minimumCost]=nodeList  \n","                \n","              \n","        return minimumCost, costToChildNodeListDict[minimumCost]  \n","                     \n","    \n","    def aoStar(self, v, backTracking):    \n","        \n","        print(\"HEURISTIC VALUES  :\", self.H)\n","        print(\"SOLUTION GRAPH    :\", self.solutionGraph)\n","        print(\"PROCESSING NODE   :\", v)\n","        print(\"-----------------------------------------------------------------------------------------\")\n","        \n","        if self.getStatus(v) >= 0:        \n","            minimumCost, childNodeList = self.computeMinimumCostChildNodes(v)\n","            self.setHeuristicNodeValue(v, minimumCost)\n","            self.setStatus(v,len(childNodeList)) \n","            \n","            solved=True                    \n","            for childNode in childNodeList:\n","                self.parent[childNode]=v\n","                if self.getStatus(childNode)!=-1:\n","                    solved=solved & False\n","            \n","            if solved==True:             \n","                self.setStatus(v,-1)     \n","                self.solutionGraph[v]=childNodeList   \n","            \n","            \n","            if v!=self.start:               \n","                self.aoStar(self.parent[v], True)   \n","                \n","            if backTracking==False:     \n","                for childNode in childNodeList:   \n","                    self.setStatus(childNode,0)   \n","                    self.aoStar(childNode, False) \n","                 \n","h2 = {'A': 1, 'B': 6, 'C': 12, 'D': 10, 'E': 4, 'F': 4, 'G': 5, 'H': 7}   \n","graph2 = {                                        \n","    'A': [[('B', 1), ('C', 1)], [('D', 1)]],       \n","    'B': [[('G', 1)], [('H', 1)]],                \n","    'D': [[('E', 1), ('F', 1)]]                   \n","}\n","\n","G2 = Graph(graph2, h2, 'A')                       \n","G2.applyAOStar()                                  \n","G2.printSolution()                                "],"metadata":{"id":"TDA4SKMXxIsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB3 CANDIDATE ELIMINATION\n","\n","import csv\n","\n","with open(\"trainingexamples.csv\") as f:\n","    csv_file = csv.reader(f)\n","    data = list(csv_file)\n","\n","    specific = data[1][:-1]\n","    general = [['?' for i in range(len(specific))] for j in range(len(specific))]\n","\n","    for i in data:\n","        if i[-1] == \"Yes\":\n","            for j in range(len(specific)):\n","                if i[j] != specific[j]:\n","                    specific[j] = \"?\"\n","                    general[j][j] = \"?\"\n","\n","        elif i[-1] == \"No\":\n","            for j in range(len(specific)):\n","                if i[j] != specific[j]:\n","                    general[j][j] = specific[j]\n","                else:\n","                    general[j][j] = \"?\"\n","\n","        print(\"\\nStep \" + str(data.index(i)+1) + \" of Candidate Elimination Algorithm\")\n","        print(specific)\n","        print(general)\n","\n","    gh = [] # gh = general Hypothesis\n","    for i in general:\n","        for j in i:\n","            if j != '?':\n","                gh.append(i)\n","                break\n","    print(\"\\nFinal Specific hypothesis:\\n\", specific)\n","    print(\"\\nFinal General hypothesis:\\n\", gh)"],"metadata":{"id":"F1Rcx8u5xIYN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB 4\n","import math\n","import csv\n","\n","def load_csv(filename):\n","    lines=csv.reader(open(filename,\"r\"))\n","    dataset = list(lines)\n","    headers = dataset.pop(0)\n","    return dataset,headers\n","\n","class Node:\n","    def __init__ (self,attribute):\n","        self.attribute=attribute\n","        self.children=[]\n","        self.answer=\"\"\n","\n","\n","def subtables(data,col,delete):  \n","    dic={}\n","    coldata=[row[col] for row in data]\n","    \n","    attr=list(set(coldata)) \n","    counts=[0]*len(attr)     \n","    r=len(data)     \n","    c=len(data[0])  \n","    for x in range(len(attr)):    \n","        for y in range(r):\n","            if data[y][col]==attr[x]:\n","                counts[x]+=1    \n","    for x in range(len(attr)):\n","        dic[attr[x]]=[[0 for i in range(c)] for j in range(counts[x])] \n","        pos=0\n","        for y in range(r):\n","            if data[y][col]==attr[x]:\n","                if delete:\n","                    del data[y][col]   \n","                dic[attr[x]][pos]=data[y] \n","                pos+=1\n","    return attr,dic   \n","\n","def entropy(S):\n","    attr=list(set(S))  \n","    if len(attr)==1:\n","        return 0    \n","    counts=[0,0]\n","    for i in range(2):\n","        counts[i]=sum([1 for x in S if attr[i]==x])/(len(S)*1.0) \n","    sums=0\n","    for cnt in counts:\n","        sums+=-1*cnt*math.log(cnt,2)  \n","    return sums\n","\n","def compute_gain(data,col): \n","    attr,dic = subtables(data,col,delete=False) \n","    total_size=len(data)  \n","    entropies=[0]*len(attr) \n","    ratio=[0]*len(attr)   \n","    total_entropy=entropy([row[-1] for row in data])\n","    \n","    for x in range(len(attr)):\n","        ratio[x]=len(dic[attr[x]])/(total_size*1.0) \n","        entropies[x]=entropy([row[-1] for row in dic[attr[x]]])\n","\n","        total_entropy-=ratio[x]*entropies[x] \n","    return total_entropy\n","\n","def build_tree(data,features):\n","    lastcol=[row[-1] for row in data]\n","    if(len(set(lastcol)))==1:  \n","        node=Node(\"\")          \n","        node.answer=lastcol[0] \n","        return node\n","    n=len(data[0])-1   \n","    gains=[0]*n        \n","    for col in range(n):   \n","        gains[col]=compute_gain(data,col)  \n","    \n","    split=gains.index(max(gains))          \n","    node=Node(features[split])             \n","                                           \n","    fea = features[:split]+features[split+1:] \n","    attr,dic=subtables(data,split,delete=True)  \n","                                                \n","    for x in range(len(attr)):                  \n","        child=build_tree(dic[attr[x]],fea)     \n","        node.children.append((attr[x],child))  \n","    return node\n","\n","def print_tree(node,level):\n","    if node.answer!=\"\":              \n","        print(\" \"*level,node.answer) \n","        return\n","    print(\" \"*level,node.attribute)  \n","    for value,n in node.children:\n","        print(\" \"*(level+1),value)\n","        print_tree(n,level+2)        \n","def classify(node,x_test,features): \n","    if node.answer!=\"\":      \n","        print(node.answer)\n","        return\n","    pos=features.index(node.attribute) \n","    for value, n in node.children:   \n","        if x_test[pos]==value:       \n","            classify(n,x_test,features) \n","\n","\n","dataset,features=load_csv(\"traintennis.csv\")\n","node1=build_tree(dataset,features)\n","print(\"The decision tree for the dataset using ID3 algorithm is\")\n","print_tree(node1,0)\n","\n","testdata,features=load_csv(\"testtennis.csv\")\n","for xtest in testdata:   \n","    print(\"The test instance:\",xtest)\n","    print(\"The label for test instance:\",end=\" \")\n","    classify(node1,xtest,features)"],"metadata":{"id":"oCadCa6bzLjc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB5 ANN\n","import numpy as np\n","X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n","y = np.array(([92], [86], [89]), dtype=float)\n","X = X/np.amax(X,axis=0)\n","y = y/100\n","\n","#Sigmoid Function\n","def sigmoid (x):\n","    return 1/(1 + np.exp(-x))\n","\n","#Derivative of Sigmoid Function\n","def derivatives_sigmoid(x):\n","    return x * (1 - x)\n","\n","#Variable initialization\n","epoch=5000 \t\n","lr=0.1 \t\t\n","inputlayer_neurons = 2 \t\t\n","hiddenlayer_neurons = 3 \t\n","output_neurons = 1 \t\t\n","\n","#weight and bias initialization\n","wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))  #2,3\n","bh=np.random.uniform(size=(1,hiddenlayer_neurons))                   #1,3\n","wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))    #3,1\n","bout=np.random.uniform(size=(1,output_neurons))                      #1,1\n","\n","for i in range(epoch):\n","#Forward Propogation \n","    hinp=np.dot(X,wh)+ bh\n","    hlayer_act = sigmoid(hinp)      \n","    outinp=np.dot(hlayer_act,wout)+ bout\n","    output = sigmoid(outinp)\n","\n","    outgrad = derivatives_sigmoid(output) \n","    hiddengrad = derivatives_sigmoid(hlayer_act)\n","    \n","    EO = y-output                   \n","    d_output = EO* outgrad\n","\n","    EH = np.dot(d_output,wout.T)      \n","    d_hiddenlayer = EH * hiddengrad\n","\n","    wout += np.dot(hlayer_act.T, d_output) *lr      \n","    wh += np.dot(X.T,d_hiddenlayer) *lr\n","\n","print(\"Input: \\n\" + str(X)) \n","print(\"Actual Output: \\n\" + str(y))\n","print(\"Predicted Output: \\n\" ,output)"],"metadata":{"id":"pMpI3C4ipK3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB6 NAIVE BAYES\n","import csv\n","import random\n","import math\n","from statistics import mean,stdev\n","\n","def loadcsv(filename):\n","    dataset = list(csv.reader(open(filename,\"r\")))\n","    for i in range(len(dataset)):\n","        dataset[i] = [float(x) for x in dataset[i]]\n","    return dataset\n","\n","def summarizeByClass(dataset):\n","    separated = {}\n","    for i in range(len(dataset)):\n","        vector = dataset[i]\n","        if (vector[-1] not in separated):\n","            separated[vector[-1]] = []\n","        separated[vector[-1]].append(vector)\n","    summaries = {}\n","    for classValue, instances in separated.items():\n","        summaries[classValue] = [(mean(attribute), stdev(attribute)) for attribute in zip(*instances)][:-1]\n","    return summaries\n","\n","def calculateProbability(x, mean, stdev):\n","    exponent = math.exp(-1*((x-mean)**2)/(2*(stdev**2)))\n","    return (1 / math.sqrt(2*math.pi*(stdev**2))) * exponent\n","\n","def predict(summaries, inputVector):\n","    probabilities = {}\n","    for classValue, classSummaries in summaries.items():\n","        probabilities[classValue] = 1\n","        for i in range(len(classSummaries)):\n","            mean, stdev = classSummaries[i]\n","            x = inputVector[i]\n","            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n","    bestLabel, bestProb = None, -1\n","    for classValue, probability in probabilities.items():\n","        if bestLabel is None or probability > bestProb:\n","            bestProb = probability\n","            bestLabel = classValue\n","    return bestLabel\n","\n","def getPredictions(testSet, summaries ):\n","    predictions = []\n","    for i in range(len(testSet)):\n","        result = predict(summaries, testSet[i])\n","        predictions.append(result)\n","    return predictions\n","\n","def getAccuracy(testSet, predictions):\n","    correct = 0\n","    for i in range(len(testSet)):\n","        if testSet[i][-1] == predictions[i]:\n","            correct += 1\n","    return (correct/(len(testSet))) * 100.0\n","\n","filename = 'diabetes2.csv'\n","splitRatio = 0.9\n","dataset = loadcsv(filename)\n","actual = []\n","trainsize=int(splitRatio*len(dataset))\n","trainingSet=dataset[:trainsize]\n","testSet=dataset[trainsize:]\n","\n","for i in range(len(testSet)):\n","\tvector = testSet[i]\n","\tactual.append(vector[-1])\n"," \n","print('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), len(trainingSet), len(testSet)))\n","summaries = summarizeByClass(trainingSet) #will have (mean,sd) for all attributes.(for class 1 & 0 separately)\n","predictions = getPredictions(testSet,summaries)\n","print('\\nActual values:\\n',actual)\n","print(\"\\nPredictions:\\n\",predictions)\n","accuracy = getAccuracy(testSet, predictions)\n","print(\"Accuracy\",accuracy)\n"],"metadata":{"id":"m4Nd4-Sgo7T7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LAB7 KMEANS VS EM\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","from sklearn.cluster import KMeans\n","from sklearn.mixture import GaussianMixture \n","import sklearn.metrics as sm\n","import pandas as pd\n","import numpy as np\n","\n","iris = datasets.load_iris()\n","\n","X = pd.DataFrame(iris.data)\n","X.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n","Y = pd.DataFrame(iris.target)\n","Y.columns = ['Targets']\n","\n","print(X)\n","print(Y)\n","colormap = np.array(['red', 'lime', 'black'])\n","\n","plt.subplot(1,2,1)\n","plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[Y.Targets], s=40)\n","plt.title('Real Clustering')\n","\n","model1 = KMeans(n_clusters=3)\n","model1.fit(X)\n","\n","plt.subplot(1,2,2)\n","plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model1.labels_], s=40)\n","plt.title('K Mean Clustering')\n","plt.show()\n","\n","model2 = GaussianMixture(n_components=3) \n","model2.fit(X)\n","\n","plt.subplot(1,2,1)\n","plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model2.predict(X)], s=40)\n","plt.title('EM Clustering')\n","plt.show()\n","\n","print(\"Actual Target is:\\n\", iris.target)\n","print(\"K Means:\\n\",model1.labels_)\n","print(\"EM:\\n\",model2.predict(X))\n","print(\"Accuracy of KMeans is \",sm.accuracy_score(Y,model1.labels_))\n","print(\"Accuracy of EM is \",sm.accuracy_score(Y, model2.predict(X)))\n"],"metadata":{"id":"TbcQHKbOpMLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esWz2yc4eKHR"},"outputs":[],"source":["#LAB 8-KNN\n","#import the dataset and library files\n","from sklearn.datasets import load_iris\n","from sklearn.neighbors import KNeighborsClassifier\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","iris_dataset=load_iris()\n","\n","#display the iris dataset\n","print(\"\\n IRIS FEATURES \\ TARGET NAMES: \\n \", iris_dataset.target_names)\n","for i in range(len(iris_dataset.target_names)):\n","    print(\"\\n[{0}]:[{1}]\".format(i,iris_dataset.target_names[i]))\n","\n","print(\"\\n IRIS DATA :\\n\",iris_dataset[\"data\"])\n","print(\"\\n Target :\\n\",iris_dataset[\"target\"])\n","\n","\n","#split the data into training and testing data\n","X_train, X_test, y_train, y_test = train_test_split(iris_dataset[\"data\"], iris_dataset[\"target\"], random_state=0)\n","\n","print(\"\\n X TRAIN \\n\", X_train)\n","print(\"\\n X TEST \\n\", X_test)\n","print(\"\\n Y TRAIN \\n\", y_train)\n","print(\"\\n Y TEST \\n\", y_test)\n","\n","#train and fit the model\n","kn = KNeighborsClassifier(n_neighbors=5)\n","kn.fit(X_train, y_train)\n","\n","#predicting from model\n","x_new = np.array([[5, 2.9, 1, 0.2]])\n","print(\"\\n XNEW \\n\",x_new)\n","prediction = kn.predict(x_new)\n","print(\"\\n Predicted target value: {}\\n\".format(prediction))\n","print(\"\\n Predicted feature name: {}\\n\".format(iris_dataset[\"target_names\"][prediction]))\n","\n","#predict for entire test dataset\n","for i in range(len(X_test)):\n","  x = X_test[i]\n","  x_new = np.array([x])\n","  prediction = kn.predict(x_new)     #predict method returns label \n","  print(\"\\n Actual : {0} {1}, Predicted :{2}{3}\".format(y_test[i],iris_dataset[\"target_names\"][y_test[i]],prediction,iris_dataset[\"target_names\"][ prediction]))\n","\n","print(\"\\n TEST SCORE[ACCURACY]: {:.2f}\\n\".format(kn.score(X_test, y_test)))"]},{"cell_type":"code","source":["#LAB9 - LOCALLY WEIGHTED REGRESSION\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def local_regression(x0, X, Y, tau):\n","    x0 = [1, x0]   \n","    X = [[1, i] for i in X]\n","    X = np.asarray(X)\n","    xw = (X.T) * np.exp(np.sum((X - x0) ** 2, axis=1) / (-2 * (tau**2)))\n","    beta = (np.linalg.pinv(xw @ X)) @ (xw @ Y)   \n","    return (beta @ x0)   \n","\n","def draw(tau):\n","    prediction = [local_regression(x0, X, Y, tau) for x0 in domain]\n","    plt.plot(X, Y, 'o', color='black')\n","    plt.plot(domain, prediction, color='red')\n","    plt.show()\n","\n","X = np.linspace(-3, 3, num=1000)\n","domain = X\n","Y = np.log(np.abs((X ** 2) - 1) + .5)\n","draw(10)\n","draw(0.1)\n","draw(0.01)\n","draw(0.001)"],"metadata":{"id":"rer0Rlgaomp8"},"execution_count":null,"outputs":[]}]}